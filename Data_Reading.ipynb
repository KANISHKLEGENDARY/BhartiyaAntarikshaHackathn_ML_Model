{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "594f5200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Timestamp  PM2.5 (¬µg/m¬≥)\n",
      "5    2024-01-01 05:00:00         124.76\n",
      "29   2024-01-02 05:00:00         133.32\n",
      "53   2024-01-03 05:00:00         119.05\n",
      "77   2024-01-04 05:00:00         133.41\n",
      "101  2024-01-05 05:00:00          91.91\n",
      "...                  ...            ...\n",
      "3965 2024-06-14 05:00:00          48.43\n",
      "3989 2024-06-15 05:00:00          49.21\n",
      "4013 2024-06-16 05:00:00          93.25\n",
      "4037 2024-06-17 05:00:00          55.74\n",
      "4061 2024-06-18 05:00:00          58.61\n",
      "\n",
      "[170 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Extracting PM2.5 levels from the CPCB data\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV\n",
    "pm_df = pd.read_csv(\"CPCB Data/City_wise_raw_data_1Hr_2024_Faridabad_1Hr.csv\")\n",
    "\n",
    "# Parse Timestamp column\n",
    "pm_df['Timestamp'] = pd.to_datetime(pm_df['Timestamp'], errors='coerce')\n",
    "\n",
    "# Create a date range for 1st to 18th June\n",
    "date_range = pd.date_range(start='2024-01-01 05:00:00', end='2024-06-18 05:00:00', freq='D')\n",
    "\n",
    "# Filter for only 05:00 data in that date range\n",
    "pm_filtered = pm_df[pm_df['Timestamp'].isin(date_range)]\n",
    "\n",
    "# Keep only Timestamp and PM2.5 columns\n",
    "pm_filtered = pm_filtered[['Timestamp', 'PM2.5 (¬µg/m¬≥)']]\n",
    "\n",
    "# Optional: Sort by date\n",
    "pm_filtered = pm_filtered.sort_values('Timestamp')\n",
    "\n",
    "# Print the results\n",
    "print(pm_filtered)\n",
    "\n",
    "# Save for training\n",
    "pm_filtered.to_csv(\"pm25_cpcb_05AM_01janto18june.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57eac91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full structure of the HDF5 file:\n",
      "Dataset: AOD ‚Äî shape: (1, 551, 551)\n",
      "Dataset: latitude ‚Äî shape: (551,)\n",
      "Dataset: longitude ‚Äî shape: (551,)\n",
      "Dataset: time ‚Äî shape: (1,)\n"
     ]
    }
   ],
   "source": [
    "#Trying to identify the shape of AOD, Latitude, and Longitude\n",
    "import h5py\n",
    "\n",
    "file_path = \"AOD Data/3DIMG_15JUN2024_0530_L2G_AOD_V02R00.h5\"\n",
    "\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    print(\"Full structure of the HDF5 file:\")\n",
    "    def print_structure(name, obj):\n",
    "        if isinstance(obj, h5py.Dataset):\n",
    "            print(f\"Dataset: {name} ‚Äî shape: {obj.shape}\")\n",
    "    f.visititems(print_structure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6baab5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date    Mean_AOD\n",
      "0  2024-06-01 -999.000000\n",
      "1  2024-06-02 -776.836670\n",
      "2  2024-06-03 -776.832703\n",
      "3  2024-06-04 -999.000000\n",
      "4  2024-06-05 -776.539917\n",
      "5  2024-06-06 -776.747070\n",
      "6  2024-06-07 -776.795715\n",
      "7  2024-06-08 -999.000000\n",
      "8  2024-06-09 -776.817932\n",
      "9  2024-06-10 -776.841675\n",
      "10 2024-06-11 -887.868042\n",
      "11 2024-06-12 -776.887695\n",
      "12 2024-06-13 -776.807800\n",
      "13 2024-06-14 -776.628784\n",
      "14 2024-06-15 -776.783203\n",
      "15 2024-06-16 -776.845398\n",
      "16 2024-06-17 -776.820801\n",
      "17 2024-06-18 -776.784424\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Folder where your HDF5 files are stored\n",
    "folder_path = \"AOD Data/\"\n",
    "\n",
    "# Define Faridabad region bounds\n",
    "lat_min, lat_max = 28.2, 28.5\n",
    "lon_min, lon_max = 77.2, 77.5\n",
    "\n",
    "# Initialize list to store results\n",
    "results = []\n",
    "\n",
    "# List all .h5 files in the folder\n",
    "for filename in sorted(os.listdir(folder_path)):\n",
    "    if filename.endswith(\".h5\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        try:\n",
    "            with h5py.File(file_path, 'r') as f:\n",
    "                # Load datasets\n",
    "                aod = f['AOD'][:].squeeze()\n",
    "                lat = f['latitude'][:]\n",
    "                lon = f['longitude'][:]\n",
    "                \n",
    "                # Flip for correct orientation\n",
    "                lat_flipped = lat[::-1]\n",
    "                aod_flipped = aod[::-1, :]\n",
    "                lon2d, lat2d = np.meshgrid(lon, lat_flipped)\n",
    "\n",
    "                # Apply mask for Faridabad region\n",
    "                mask = (lat2d >= lat_min) & (lat2d <= lat_max) & (lon2d >= lon_min) & (lon2d <= lon_max)\n",
    "                aod_faridabad_values = aod_flipped[mask]\n",
    "                mean_aod = np.nanmean(aod_faridabad_values)\n",
    "\n",
    "                # Extract date from filename (assumes format: 3DIMG_15JUN2024_0530_....h5)\n",
    "                date_str = filename.split(\"_\")[1]\n",
    "                date = pd.to_datetime(date_str, format='%d%b%Y')\n",
    "\n",
    "                # Append to results\n",
    "                results.append({'Date': date, 'Mean_AOD': mean_aod})\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {filename}: {e}\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "df.sort_values('Date', inplace=True)\n",
    "\n",
    "# Save to CSV for training\n",
    "df.to_csv(\"mean_aod_faridabad.csv\", index=False)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70a06249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  Mean_AOD           Timestamp  PM2.5\n",
      "0 2024-06-01 -999.0000 2024-06-01 05:00:00  76.40\n",
      "1 2024-06-02 -776.8367 2024-06-02 05:00:00  74.98\n",
      "2 2024-06-03 -776.8327 2024-06-03 05:00:00  77.86\n",
      "3 2024-06-04 -999.0000 2024-06-04 05:00:00  55.40\n",
      "4 2024-06-05 -776.5399 2024-06-05 05:00:00  88.99\n"
     ]
    }
   ],
   "source": [
    "#Combine AOD and PM2.5 into One Dataframe\n",
    "import pandas as pd\n",
    "\n",
    "# Load both datasets\n",
    "aod_df = pd.read_csv(\"mean_aod_faridabad.csv\")\n",
    "pm_df = pd.read_csv(\"pm25_cpcb_05AM_1to18june.csv\")\n",
    "\n",
    "# Convert date columns to datetime\n",
    "aod_df['Date'] = pd.to_datetime(aod_df['Date'])\n",
    "pm_df['Timestamp'] = pd.to_datetime(pm_df['Timestamp'])\n",
    "\n",
    "# Extract just the date part but KEEP datetime64[ns] type\n",
    "pm_df['Date'] = pm_df['Timestamp'].dt.normalize()\n",
    "\n",
    "# Merge on Date\n",
    "combined_df = pd.merge(aod_df, pm_df, left_on='Date', right_on='Date')\n",
    "\n",
    "# Rename for simplicity\n",
    "combined_df.rename(columns={\"PM2.5 (¬µg/m¬≥)\": \"PM2.5\"}, inplace=True)\n",
    "\n",
    "print(combined_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53cb4c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error on test set: 16.329789183384506\n",
      "Predicted PM2.5 for 2024-06-19 at 05:00: 59.31425022570035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91931\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Training a simple linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Features and target\n",
    "X = combined_df[['Mean_AOD']]  # Feature\n",
    "y = combined_df['PM2.5']       # Target\n",
    "\n",
    "# Train-test split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Mean Absolute Error on test set:\", mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "#Predicting PM2.5 for 19th June\n",
    "aod_19_june = 0.97  # Replace this with your actual computed value\n",
    "predicted_pm = model.predict([[aod_19_june]])\n",
    "print(\"Predicted PM2.5 for 2024-06-19 at 05:00:\", predicted_pm[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "193f4119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Timestamp  PM2.5 (¬µg/m¬≥)\n",
      "4085 2024-06-19 05:00:00           52.8\n"
     ]
    }
   ],
   "source": [
    "#Finding PM2.5 concentration for a single day\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"CPCB Data/City_wise_raw_data_1Hr_2024_Faridabad_1Hr.csv\")\n",
    "df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"], errors = \"coerce\")\n",
    "target_time = pd.Timestamp(\"2024-06-19 05:00:00\")\n",
    "pm_at_time = df[df[\"Timestamp\"] == target_time]\n",
    "print(pm_at_time[[\"Timestamp\", \"PM2.5 (¬µg/m¬≥)\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db348329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model Evaluation:\n",
      "MAE: 7.778910714285711\n",
      "RMSE: 8.834053260522328\n",
      "R¬≤ Score: 0.5988373888613501\n",
      "\n",
      "üîÆ Predicted PM2.5 for 19 June 2024 at 05:00: 77.30559999999991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91931\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Prediction by Random Forest\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Load and merge the datasets\n",
    "aod_df = pd.read_csv(\"mean_aod_faridabad.csv\")\n",
    "pm_df = pd.read_csv(\"pm25_cpcb_05AM_1to18june.csv\")\n",
    "\n",
    "# Convert to datetime\n",
    "aod_df['Date'] = pd.to_datetime(aod_df['Date'])\n",
    "pm_df['Timestamp'] = pd.to_datetime(pm_df['Timestamp'])\n",
    "pm_df['Date'] = pm_df['Timestamp'].dt.normalize()\n",
    "\n",
    "# Merge on 'Date'\n",
    "combined_df = pd.merge(aod_df, pm_df, on='Date')\n",
    "combined_df.rename(columns={\"PM2.5 (¬µg/m¬≥)\": \"PM2.5\"}, inplace=True)\n",
    "\n",
    "# Select features and target\n",
    "X = combined_df[['Mean_AOD']]\n",
    "y = combined_df['PM2.5']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Random Forest Regressor\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"‚úÖ Model Evaluation:\")\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print(\"R¬≤ Score:\", r2_score(y_test, y_pred))\n",
    "\n",
    "#Prediction for 19th June\n",
    "aod_19_june = 0.97\n",
    "\n",
    "predicted_pm25 = rf.predict([[aod_19_june]])\n",
    "print(\"\\nüîÆ Predicted PM2.5 for 19 June 2024 at 05:00:\", predicted_pm25[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32c9b975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Evaluation:\n",
      "MAE: 29.85470588235294\n",
      "RMSE: 38.29453567091755\n",
      "R¬≤: -0.12154633339605092\n",
      "\n",
      "üîÆ Predicted PM2.5 for 19 June 2024 at 05:30 IST: 123.29020000000006\n"
     ]
    }
   ],
   "source": [
    "#Combining MOSDAC and CPCB data with MERRA and predicting the PM2.5 Level\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from netCDF4 import Dataset, num2date\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "# ---------- Step 1: Load INSAT AOD from CSV ----------\n",
    "aod_df = pd.read_csv(\"aod_data.csv\")\n",
    "aod_df['Date'] = pd.to_datetime(aod_df['Date'])  # üîÑ Convert to datetime for merging\n",
    "# print(aod_df.head())\n",
    "\n",
    "# ---------- Step 2: Load CPCB PM2.5 ----------\n",
    "pm_df = pd.read_csv(\"pm25_cpcb_05AM_01janto18june.csv\")\n",
    "pm_df['Timestamp'] = pd.to_datetime(pm_df['Timestamp'])\n",
    "pm_df['Date'] = pm_df['Timestamp'].dt.normalize()\n",
    "\n",
    "# ---------- Step 3: Load MERRA .nc4 files ----------\n",
    "def extract_merra_features(nc_folder):\n",
    "    records = []\n",
    "    for file in os.listdir(nc_folder):\n",
    "        if file.endswith(\".nc\"):\n",
    "            ds = Dataset(os.path.join(nc_folder, file), 'r')\n",
    "\n",
    "            time_var = ds.variables['time']\n",
    "            times = num2date(time_var[:], units=time_var.units, only_use_cftime_datetimes=False)\n",
    "\n",
    "            ps = ds.variables['PS'][:, 0, 0]\n",
    "            qv2m = ds.variables['QV2M'][:, 0, 0]\n",
    "            t2m = ds.variables['T2M'][:, 0, 0]\n",
    "            ts = ds.variables['TS'][:, 0, 0]\n",
    "            u10m = ds.variables['U10M'][:, 0, 0]\n",
    "            # v10m = ds.variables['V10M'][:, 0, 0]\n",
    "            qv10m = ds.variables['QV10M'][:, 0, 0]\n",
    "            slp = ds.variables['SLP'][:, 0, 0]\n",
    "            t10m = ds.variables['T10M'][:, 0, 0]\n",
    "            t2mdew = ds.variables['T2MDEW'][:, 0, 0]\n",
    "            tqi = ds.variables['TQI'][:, 0, 0]\n",
    "            tql = ds.variables['TQL'][:, 0, 0]\n",
    "            # u2m = ds.variables['U2M'][:, 0, 0]\n",
    "\n",
    "            for i in range(len(times)):\n",
    "                # Ensure times[i] is a native datetime object\n",
    "                date_val = times[i]\n",
    "                if hasattr(date_val, 'year'):\n",
    "                    date_val = datetime(date_val.year, date_val.month, date_val.day)\n",
    "\n",
    "                records.append({\n",
    "                    \"Date\": date_val,\n",
    "                    \"PS\": ps[i],\n",
    "                    \"QV2M\": qv2m[i],\n",
    "                    \"T2M\": t2m[i],\n",
    "                    \"TS\": ts[i],\n",
    "                    \"U10M\": u10m[i],\n",
    "                    \"QV10M\": qv10m[i],\n",
    "                    \"SLP\": slp[i],\n",
    "                    \"T10M\": t10m[i],\n",
    "                    \"T2MDEW\": t2mdew[i],\n",
    "                    \"TQI\": tqi[i],\n",
    "                    \"TQL\": tql[i],\n",
    "                    # \"U2M\": u2m[i]\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "merra_df = extract_merra_features(\"merra_downloads\")  # üìÅ Folder containing .nc4 files\n",
    "merra_df = merra_df.groupby(\"Date\").mean().reset_index()\n",
    "\n",
    "aod_df['Date'] = pd.to_datetime(aod_df['Date'])\n",
    "pm_df['Date'] = pd.to_datetime(pm_df['Date'])\n",
    "merra_df['Date'] = pd.to_datetime(merra_df['Date'])  # ‚úÖ This fixes the issue\n",
    "\n",
    "# print(aod_df.dtypes)\n",
    "# print(pm_df.dtypes)\n",
    "# print(merra_df.dtypes)\n",
    "\n",
    "# print(f\"AOD records: {len(aod_df)}\")\n",
    "# print(f\"CPCB records: {len(pm_df)}\")\n",
    "# print(f\"MERRA records: {len(merra_df)}\")\n",
    "\n",
    "# ---------- Step 4: Merge All ----------\n",
    "combined_df = pd.merge(aod_df, pm_df, on=\"Date\")\n",
    "# print(f\"After merging AOD + CPCB: {len(combined_df)} records\")\n",
    "\n",
    "combined_df = pd.merge(combined_df, merra_df, on=\"Date\")\n",
    "# print(f\"After merging with MERRA: {len(combined_df)} records\")\n",
    "\n",
    "# print(\"üîç AOD dates:\", aod_df['Date'].unique())\n",
    "# print(\"üîç CPCB dates:\", pm_df['Date'].unique())\n",
    "# print(\"üîç MERRA dates:\", merra_df['Date'].unique())\n",
    "\n",
    "\n",
    "# ---------- Step 5: ML Model ----------\n",
    "features = ['Mean_AOD', 'PS', 'QV2M', 'T2M', 'TS', 'U10M', 'U10M', 'QV10M', 'SLP', 'T10M', 'T2MDEW', 'TQI', 'TQL']\n",
    "X = combined_df[features]\n",
    "y = combined_df['PM2.5 (¬µg/m¬≥)']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"‚úÖ Evaluation:\")\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print(\"R¬≤:\", r2_score(y_test, y_pred))\n",
    "\n",
    "# ---------- Step 5: ML Model (Linear Regression) ----------\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# features = ['Mean_AOD', 'PS', 'QV2M', 'T2M', 'TS', 'U10M', 'V10M']\n",
    "# X = combined_df[features]\n",
    "# y = combined_df['PM2.5 (¬µg/m¬≥)']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# lr = LinearRegression()\n",
    "# lr.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = lr.predict(X_test)\n",
    "\n",
    "# print(\"‚úÖ Evaluation (Linear Regression):\")\n",
    "# print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "# print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "# print(\"R¬≤:\", r2_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# ---------- Step 6: Predict for 19 June ----------\n",
    "# Replace with actual June 19 values from your MERRA and AOD\n",
    "june_19 = {\n",
    "    \"Mean_AOD\": [0.97],\n",
    "    \"PS\": [96736.921],\n",
    "    \"QV2M\": [0.012],\n",
    "    \"T2M\": [318.42],\n",
    "    \"TS\": [321],\n",
    "    \"U10M\": [7.13],\n",
    "    \"QV10M\": [0.01],\n",
    "    \"SLP\": [98938.65],\n",
    "    \"T10M\": [317.61],\n",
    "    \"T2MDEW\": [289.67],\n",
    "    \"TQI\": [2.6],\n",
    "    \"TQL\": [0.0],\n",
    "    # \"U2M\": [5.41]\n",
    "}\n",
    "june_19_df = pd.DataFrame(june_19)\n",
    "june_19_df = june_19_df[features]\n",
    "pred_pm = rf.predict(june_19_df)\n",
    "print(\"\\nüîÆ Predicted PM2.5 for 19 June 2024 at 05:30 IST:\", pred_pm[0])\n",
    "\n",
    "# import seaborn as sns\n",
    "# sns.heatmap(combined_df.corr(), annot=True)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.scatter(y_test, y_pred)\n",
    "# plt.xlabel(\"Actual PM2.5\")\n",
    "# plt.ylabel(\"Predicted PM2.5\")\n",
    "# plt.title(\"Actual vs Predicted PM2.5\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74f151a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Keys in file: ['AOD', 'latitude', 'longitude', 'time']\n",
      "üìê AOD shape: (1, 551, 551)\n",
      "üß≠ Latitude shape: (551,)\n",
      "üß≠ Longitude shape: (551,)\n",
      "üîé Nearest index ‚Äî lat: 166 lon: 322\n",
      "üìå AOD value at Faridabad: 0.779472\n",
      "üìÜ Date parsed from filename: 2024-05-01\n",
      "‚úÖ Final Record: {'Date': datetime.date(2024, 5, 1), 'Mean_AOD': 0.779472}\n"
     ]
    }
   ],
   "source": [
    "#To read AOD value from a single .h5 file\n",
    "import h5py\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# üìç Location of interest: Faridabad (approx.)\n",
    "target_lat = 28.4\n",
    "target_lon = 77.3\n",
    "\n",
    "# üìÑ Path to one .h5 file (example)\n",
    "file_path = \"aod_folder/3DIMG_01MAY2024_0530_L2G_AOD_V02R00.h5\"\n",
    "\n",
    "# ‚úÖ Read and extract AOD value\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    print(\"üîç Keys in file:\", list(f.keys()))  # Show root-level keys\n",
    "\n",
    "    # Check if required datasets are present\n",
    "    if 'AOD' in f and 'latitude' in f and 'longitude' in f:\n",
    "        aod_data = f['AOD'][:]           # 2D array of AOD\n",
    "        latitudes = f['latitude'][:]     # 1D array\n",
    "        longitudes = f['longitude'][:]   # 1D array\n",
    "\n",
    "        print(\"üìê AOD shape:\", aod_data.shape)\n",
    "        print(\"üß≠ Latitude shape:\", latitudes.shape)\n",
    "        print(\"üß≠ Longitude shape:\", longitudes.shape)\n",
    "\n",
    "        # Find nearest grid index to target lat/lon\n",
    "        lat_idx = (np.abs(latitudes - target_lat)).argmin()\n",
    "        lon_idx = (np.abs(longitudes - target_lon)).argmin()\n",
    "        print(\"üîé Nearest index ‚Äî lat:\", lat_idx, \"lon:\", lon_idx)\n",
    "\n",
    "        # Handle possible shape issues\n",
    "        try:\n",
    "            aod_value = aod_data[0, lat_idx, lon_idx]\n",
    "            print(\"üìå AOD value at Faridabad:\", aod_value)\n",
    "        except IndexError as e:\n",
    "            print(\"‚ùå IndexError while accessing AOD value:\", e)\n",
    "            aod_value = np.nan\n",
    "    else:\n",
    "        print(\"‚ùå One or more required datasets not found in file.\")\n",
    "        aod_value = np.nan\n",
    "\n",
    "    # Parse date from filename\n",
    "    filename = os.path.basename(file_path)\n",
    "    try:\n",
    "        date_str = filename.split(\"_\")[1]  # '01JUN2024'\n",
    "        date_obj = datetime.strptime(date_str, \"%d%b%Y\").date()\n",
    "        print(\"üìÜ Date parsed from filename:\", date_obj)\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Error parsing date from filename:\", e)\n",
    "        date_obj = None\n",
    "\n",
    "    # Store result\n",
    "    record = {\n",
    "        \"Date\": date_obj,\n",
    "        \"Mean_AOD\": aod_value\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Final Record:\", record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7935251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved all AOD values to aod_data.csv\n"
     ]
    }
   ],
   "source": [
    "#Merging all the .h5 into a single csv file\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "def extract_aod_from_folder(folder_path):\n",
    "    records = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".h5\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                with h5py.File(file_path, 'r') as f:\n",
    "                    # Ensure keys exist (some files might be corrupt)\n",
    "                    if 'AOD' not in f or 'latitude' not in f or 'longitude' not in f:\n",
    "                        continue\n",
    "\n",
    "                    aod_data = f['AOD'][:]\n",
    "                    latitudes = f['latitude'][:]\n",
    "                    longitudes = f['longitude'][:]\n",
    "\n",
    "                    # Find nearest point to Faridabad\n",
    "                    lat_idx = (np.abs(latitudes - 28.4)).argmin()\n",
    "                    lon_idx = (np.abs(longitudes - 77.3)).argmin()\n",
    "\n",
    "                    # Fix for shape mismatch\n",
    "                    if aod_data.ndim == 3 and lat_idx < aod_data.shape[1] and lon_idx < aod_data.shape[2]:\n",
    "                        aod_val = aod_data[0, lat_idx, lon_idx]\n",
    "                    else:\n",
    "                        aod_val = np.nan  # skip if shape mismatch\n",
    "\n",
    "                    # Extract date from filename\n",
    "                    date_str = filename.split(\"_\")[1]  # '01JUN2024'\n",
    "                    date_obj = datetime.strptime(date_str, \"%d%b%Y\").date()\n",
    "\n",
    "                    records.append({\n",
    "                        \"Date\": date_obj,\n",
    "                        \"Mean_AOD\": aod_val\n",
    "                    })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Failed for {filename}: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# üîÅ Extract from all files\n",
    "aod_df = extract_aod_from_folder(\"aod_folder\")\n",
    "\n",
    "# üíæ Save to CSV\n",
    "aod_df.to_csv(\"aod_data.csv\", index=False)\n",
    "print(\"‚úÖ Saved all AOD values to aod_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c1197b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PS': [96736.921875], 'QV2M': [0.012161721475422382], 'T2M': [318.42095947265625], 'TS': [320.8171691894531], 'U10M': [7.130051136016846], 'QV10M': [0.012165547348558903], 'SLP': [98938.65625], 'T10M': [317.6146240234375], 'T2MDEW': [289.6773986816406], 'TQI': [2.5697052478790283e-05], 'TQL': [0.0], 'U2M': [5.413762092590332]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\M'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\M'\n",
      "C:\\Users\\91931\\AppData\\Local\\Temp\\ipykernel_18268\\3832593676.py:5: SyntaxWarning: invalid escape sequence '\\M'\n",
      "  file_path = \"merra_downloads\\MERRA2_400.tavg1_2d_slv_Nx.20240619.SUB.nc\"\n"
     ]
    }
   ],
   "source": [
    "#Reading the MERRA Varible values from the file\n",
    "import xarray as xr\n",
    "\n",
    "# Load NetCDF file\n",
    "file_path = \"merra_downloads\\MERRA2_400.tavg1_2d_slv_Nx.20240619.SUB.nc\"\n",
    "ds = xr.open_dataset(file_path)\n",
    "\n",
    "# üîç Step 1: Define coordinates of Faridabad (approx)\n",
    "target_lat = 28.41\n",
    "target_lon = 77.31\n",
    "\n",
    "# üîç Step 2: Select the nearest location\n",
    "nearest_lat = ds.sel(lat=target_lat, method=\"nearest\").lat.values\n",
    "nearest_lon = ds.sel(lon=target_lon, method=\"nearest\").lon.values\n",
    "\n",
    "# üîç Step 3: Select the first time step (if only one day is present)\n",
    "time_step = ds.time.values[0]\n",
    "\n",
    "# üîç Step 4: Extract values for each variable at that location and time\n",
    "june_19 = {\n",
    "    \"PS\":     [float(ds[\"PS\"].sel(time=time_step, lat=nearest_lat, lon=nearest_lon).values)],\n",
    "    \"QV2M\":   [float(ds[\"QV2M\"].sel(time=time_step, lat=nearest_lat, lon=nearest_lon).values)],\n",
    "    \"T2M\":    [float(ds[\"T2M\"].sel(time=time_step, lat=nearest_lat, lon=nearest_lon).values)],\n",
    "    \"TS\":     [float(ds[\"TS\"].sel(time=time_step, lat=nearest_lat, lon=nearest_lon).values)],\n",
    "    \"U10M\":   [float(ds[\"U10M\"].sel(time=time_step, lat=nearest_lat, lon=nearest_lon).values)],\n",
    "    \"QV10M\":   [float(ds[\"QV10M\"].sel(time=time_step, lat=nearest_lat, lon=nearest_lon).values)],\n",
    "    \"SLP\":   [float(ds[\"SLP\"].sel(time=time_step, lat=nearest_lat, lon=nearest_lon).values)],\n",
    "    \"T10M\":   [float(ds[\"T10M\"].sel(time=time_step, lat=nearest_lat, lon=nearest_lon).values)],\n",
    "    \"T2MDEW\":   [float(ds[\"T2MDEW\"].sel(time=time_step, lat=nearest_lat, lon=nearest_lon).values)],\n",
    "    \"TQI\":   [float(ds[\"TQI\"].sel(time=time_step, lat=nearest_lat, lon=nearest_lon).values)],\n",
    "    \"TQL\":   [float(ds[\"TQL\"].sel(time=time_step, lat=nearest_lat, lon=nearest_lon).values)],\n",
    "    \"U2M\":   [float(ds[\"U2M\"].sel(time=time_step, lat=nearest_lat, lon=nearest_lon).values)],\n",
    "    # \"Mean_AOD\": [0.97]  # Add manually or fetch from INSAT/CPCB if needed\n",
    "}\n",
    "\n",
    "print(june_19)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
