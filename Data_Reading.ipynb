{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "594f5200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Timestamp  PM2.5 (µg/m³)\n",
      "5    2024-01-01 05:00:00         124.76\n",
      "29   2024-01-02 05:00:00         133.32\n",
      "53   2024-01-03 05:00:00         119.05\n",
      "77   2024-01-04 05:00:00         133.41\n",
      "101  2024-01-05 05:00:00          91.91\n",
      "...                  ...            ...\n",
      "3965 2024-06-14 05:00:00          48.43\n",
      "3989 2024-06-15 05:00:00          49.21\n",
      "4013 2024-06-16 05:00:00          93.25\n",
      "4037 2024-06-17 05:00:00          55.74\n",
      "4061 2024-06-18 05:00:00          58.61\n",
      "\n",
      "[170 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Extracting PM2.5 levels from the CPCB data\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV\n",
    "pm_df = pd.read_csv(\"CPCB Data/City_wise_raw_data_1Hr_2024_Faridabad_1Hr.csv\")\n",
    "\n",
    "# Parse Timestamp column\n",
    "pm_df['Timestamp'] = pd.to_datetime(pm_df['Timestamp'], errors='coerce')\n",
    "\n",
    "# Create a date range for 1st to 18th June\n",
    "date_range = pd.date_range(start='2024-01-01 05:00:00', end='2024-06-18 05:00:00', freq='D')\n",
    "\n",
    "# Filter for only 05:00 data in that date range\n",
    "pm_filtered = pm_df[pm_df['Timestamp'].isin(date_range)]\n",
    "\n",
    "# Keep only Timestamp and PM2.5 columns\n",
    "pm_filtered = pm_filtered[['Timestamp', 'PM2.5 (µg/m³)']]\n",
    "\n",
    "# Optional: Sort by date\n",
    "pm_filtered = pm_filtered.sort_values('Timestamp')\n",
    "\n",
    "# Print the results\n",
    "print(pm_filtered)\n",
    "\n",
    "# Save for training\n",
    "pm_filtered.to_csv(\"pm25_cpcb_05AM_01janto18june.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57eac91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full structure of the HDF5 file:\n",
      "Dataset: AOD — shape: (1, 551, 551)\n",
      "Dataset: latitude — shape: (551,)\n",
      "Dataset: longitude — shape: (551,)\n",
      "Dataset: time — shape: (1,)\n"
     ]
    }
   ],
   "source": [
    "#Trying to identify the shape of AOD, Latitude, and Longitude\n",
    "import h5py\n",
    "\n",
    "file_path = \"AOD Data/3DIMG_15JUN2024_0530_L2G_AOD_V02R00.h5\"\n",
    "\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    print(\"Full structure of the HDF5 file:\")\n",
    "    def print_structure(name, obj):\n",
    "        if isinstance(obj, h5py.Dataset):\n",
    "            print(f\"Dataset: {name} — shape: {obj.shape}\")\n",
    "    f.visititems(print_structure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6baab5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date    Mean_AOD\n",
      "0  2024-06-01 -999.000000\n",
      "1  2024-06-02 -776.836670\n",
      "2  2024-06-03 -776.832703\n",
      "3  2024-06-04 -999.000000\n",
      "4  2024-06-05 -776.539917\n",
      "5  2024-06-06 -776.747070\n",
      "6  2024-06-07 -776.795715\n",
      "7  2024-06-08 -999.000000\n",
      "8  2024-06-09 -776.817932\n",
      "9  2024-06-10 -776.841675\n",
      "10 2024-06-11 -887.868042\n",
      "11 2024-06-12 -776.887695\n",
      "12 2024-06-13 -776.807800\n",
      "13 2024-06-14 -776.628784\n",
      "14 2024-06-15 -776.783203\n",
      "15 2024-06-16 -776.845398\n",
      "16 2024-06-17 -776.820801\n",
      "17 2024-06-18 -776.784424\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Folder where your HDF5 files are stored\n",
    "folder_path = \"AOD Data/\"\n",
    "\n",
    "# Define Faridabad region bounds\n",
    "lat_min, lat_max = 28.2, 28.5\n",
    "lon_min, lon_max = 77.2, 77.5\n",
    "\n",
    "# Initialize list to store results\n",
    "results = []\n",
    "\n",
    "# List all .h5 files in the folder\n",
    "for filename in sorted(os.listdir(folder_path)):\n",
    "    if filename.endswith(\".h5\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        try:\n",
    "            with h5py.File(file_path, 'r') as f:\n",
    "                # Load datasets\n",
    "                aod = f['AOD'][:].squeeze()\n",
    "                lat = f['latitude'][:]\n",
    "                lon = f['longitude'][:]\n",
    "                \n",
    "                # Flip for correct orientation\n",
    "                lat_flipped = lat[::-1]\n",
    "                aod_flipped = aod[::-1, :]\n",
    "                lon2d, lat2d = np.meshgrid(lon, lat_flipped)\n",
    "\n",
    "                # Apply mask for Faridabad region\n",
    "                mask = (lat2d >= lat_min) & (lat2d <= lat_max) & (lon2d >= lon_min) & (lon2d <= lon_max)\n",
    "                aod_faridabad_values = aod_flipped[mask]\n",
    "                mean_aod = np.nanmean(aod_faridabad_values)\n",
    "\n",
    "                # Extract date from filename (assumes format: 3DIMG_15JUN2024_0530_....h5)\n",
    "                date_str = filename.split(\"_\")[1]\n",
    "                date = pd.to_datetime(date_str, format='%d%b%Y')\n",
    "\n",
    "                # Append to results\n",
    "                results.append({'Date': date, 'Mean_AOD': mean_aod})\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {filename}: {e}\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "df.sort_values('Date', inplace=True)\n",
    "\n",
    "# Save to CSV for training\n",
    "df.to_csv(\"mean_aod_faridabad.csv\", index=False)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70a06249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  Mean_AOD           Timestamp  PM2.5\n",
      "0 2024-06-01 -999.0000 2024-06-01 05:00:00  76.40\n",
      "1 2024-06-02 -776.8367 2024-06-02 05:00:00  74.98\n",
      "2 2024-06-03 -776.8327 2024-06-03 05:00:00  77.86\n",
      "3 2024-06-04 -999.0000 2024-06-04 05:00:00  55.40\n",
      "4 2024-06-05 -776.5399 2024-06-05 05:00:00  88.99\n"
     ]
    }
   ],
   "source": [
    "#Combine AOD and PM2.5 into One Dataframe\n",
    "import pandas as pd\n",
    "\n",
    "# Load both datasets\n",
    "aod_df = pd.read_csv(\"mean_aod_faridabad.csv\")\n",
    "pm_df = pd.read_csv(\"pm25_cpcb_05AM_1to18june.csv\")\n",
    "\n",
    "# Convert date columns to datetime\n",
    "aod_df['Date'] = pd.to_datetime(aod_df['Date'])\n",
    "pm_df['Timestamp'] = pd.to_datetime(pm_df['Timestamp'])\n",
    "\n",
    "# Extract just the date part but KEEP datetime64[ns] type\n",
    "pm_df['Date'] = pm_df['Timestamp'].dt.normalize()\n",
    "\n",
    "# Merge on Date\n",
    "combined_df = pd.merge(aod_df, pm_df, left_on='Date', right_on='Date')\n",
    "\n",
    "# Rename for simplicity\n",
    "combined_df.rename(columns={\"PM2.5 (µg/m³)\": \"PM2.5\"}, inplace=True)\n",
    "\n",
    "print(combined_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53cb4c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error on test set: 16.329789183384506\n",
      "Predicted PM2.5 for 2024-06-19 at 05:00: 59.31425022570035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91931\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Training a simple linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Features and target\n",
    "X = combined_df[['Mean_AOD']]  # Feature\n",
    "y = combined_df['PM2.5']       # Target\n",
    "\n",
    "# Train-test split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Mean Absolute Error on test set:\", mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "#Predicting PM2.5 for 19th June\n",
    "aod_19_june = 0.97  # Replace this with your actual computed value\n",
    "predicted_pm = model.predict([[aod_19_june]])\n",
    "print(\"Predicted PM2.5 for 2024-06-19 at 05:00:\", predicted_pm[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "193f4119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Timestamp  PM2.5 (µg/m³)\n",
      "3149 2024-05-11 05:00:00          88.95\n"
     ]
    }
   ],
   "source": [
    "#Finding PM2.5 concentration for a single day\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"CPCB Data/City_wise_raw_data_1Hr_2024_Faridabad_1Hr.csv\")\n",
    "df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"], errors = \"coerce\")\n",
    "target_time = pd.Timestamp(\"2024-05-11 05:00:00\")\n",
    "pm_at_time = df[df[\"Timestamp\"] == target_time]\n",
    "print(pm_at_time[[\"Timestamp\", \"PM2.5 (µg/m³)\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db348329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model Evaluation:\n",
      "MAE: 7.778910714285711\n",
      "RMSE: 8.834053260522328\n",
      "R² Score: 0.5988373888613501\n",
      "\n",
      "🔮 Predicted PM2.5 for 19 June 2024 at 05:00: 77.30559999999991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91931\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Prediction by Random Forest\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Load and merge the datasets\n",
    "aod_df = pd.read_csv(\"mean_aod_faridabad.csv\")\n",
    "pm_df = pd.read_csv(\"pm25_cpcb_05AM_1to18june.csv\")\n",
    "\n",
    "# Convert to datetime\n",
    "aod_df['Date'] = pd.to_datetime(aod_df['Date'])\n",
    "pm_df['Timestamp'] = pd.to_datetime(pm_df['Timestamp'])\n",
    "pm_df['Date'] = pm_df['Timestamp'].dt.normalize()\n",
    "\n",
    "# Merge on 'Date'\n",
    "combined_df = pd.merge(aod_df, pm_df, on='Date')\n",
    "combined_df.rename(columns={\"PM2.5 (µg/m³)\": \"PM2.5\"}, inplace=True)\n",
    "\n",
    "# Select features and target\n",
    "X = combined_df[['Mean_AOD']]\n",
    "y = combined_df['PM2.5']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Random Forest Regressor\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"✅ Model Evaluation:\")\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print(\"R² Score:\", r2_score(y_test, y_pred))\n",
    "\n",
    "#Prediction for 19th June\n",
    "aod_19_june = 0.97\n",
    "\n",
    "predicted_pm25 = rf.predict([[aod_19_june]])\n",
    "print(\"\\n🔮 Predicted PM2.5 for 19 June 2024 at 05:00:\", predicted_pm25[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c9b975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Evaluation:\n",
      "MAE: 28.026991176470588\n",
      "RMSE: 36.08490578960144\n",
      "R²: 0.0041481018634580424\n",
      "\n",
      "🔮 Predicted PM2.5 for 11 May 2024 at 05:30 IST: 96.84259999999999\n"
     ]
    }
   ],
   "source": [
    "#Combining MOSDAC and CPCB data with MERRA and predicting the PM2.5 Level\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from netCDF4 import Dataset, num2date\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "# ---------- Step 1: Load INSAT AOD from CSV ----------\n",
    "aod_df = pd.read_csv(\"aod_data.csv\")\n",
    "aod_df['Date'] = pd.to_datetime(aod_df['Date'])  # 🔄 Convert to datetime for merging\n",
    "# print(aod_df.head())\n",
    "\n",
    "# ---------- Step 2: Load CPCB PM2.5 ----------\n",
    "pm_df = pd.read_csv(\"pm25_cpcb_05AM_01janto18june.csv\")\n",
    "pm_df['Timestamp'] = pd.to_datetime(pm_df['Timestamp'])\n",
    "pm_df['Date'] = pm_df['Timestamp'].dt.normalize()\n",
    "\n",
    "# ---------- Step 3: Load MERRA .nc4 files ----------\n",
    "def extract_merra_features(nc_folder):\n",
    "    records = []\n",
    "    for file in os.listdir(nc_folder):\n",
    "        if file.endswith(\".nc\"):\n",
    "            ds = Dataset(os.path.join(nc_folder, file), 'r')\n",
    "\n",
    "            time_var = ds.variables['time']\n",
    "            times = num2date(time_var[:], units=time_var.units, only_use_cftime_datetimes=False)\n",
    "\n",
    "            ps = ds.variables['PS'][:, 0, 0]\n",
    "            qv2m = ds.variables['QV2M'][:, 0, 0]\n",
    "            t2m = ds.variables['T2M'][:, 0, 0]\n",
    "            ts = ds.variables['TS'][:, 0, 0]\n",
    "            u10m = ds.variables['U10M'][:, 0, 0]\n",
    "            # v10m = ds.variables['V10M'][:, 0, 0]\n",
    "            qv10m = ds.variables['QV10M'][:, 0, 0]\n",
    "            slp = ds.variables['SLP'][:, 0, 0]\n",
    "            t10m = ds.variables['T10M'][:, 0, 0]\n",
    "            t2mdew = ds.variables['T2MDEW'][:, 0, 0]\n",
    "            tqi = ds.variables['TQI'][:, 0, 0]\n",
    "            tql = ds.variables['TQL'][:, 0, 0]\n",
    "\n",
    "            for i in range(len(times)):\n",
    "                # Ensure times[i] is a native datetime object\n",
    "                date_val = times[i]\n",
    "                if hasattr(date_val, 'year'):\n",
    "                    date_val = datetime(date_val.year, date_val.month, date_val.day)\n",
    "\n",
    "                records.append({\n",
    "                    \"Date\": date_val,\n",
    "                    \"PS\": ps[i],\n",
    "                    \"QV2M\": qv2m[i],\n",
    "                    \"T2M\": t2m[i],\n",
    "                    \"TS\": ts[i],\n",
    "                    \"U10M\": u10m[i],\n",
    "                    \"QV10M\": qv10m[i],\n",
    "                    \"SLP\": slp[i],\n",
    "                    \"T10M\": t10m[i],\n",
    "                    \"T2MDEW\": t2mdew[i],\n",
    "                    \"TQI\": tqi[i],\n",
    "                    \"TQL\": tql[i],\n",
    "                    # \"U2M\": u2m[i]\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "merra_df = extract_merra_features(\"merra_downloads\")  # 📁 Folder containing .nc4 files\n",
    "merra_df = merra_df.groupby(\"Date\").mean().reset_index()\n",
    "\n",
    "aod_df['Date'] = pd.to_datetime(aod_df['Date'])\n",
    "pm_df['Date'] = pd.to_datetime(pm_df['Date'])\n",
    "merra_df['Date'] = pd.to_datetime(merra_df['Date'])  # ✅ This fixes the issue\n",
    "\n",
    "# print(aod_df.dtypes)\n",
    "# print(pm_df.dtypes)\n",
    "# print(merra_df.dtypes)\n",
    "\n",
    "# print(f\"AOD records: {len(aod_df)}\")\n",
    "# print(f\"CPCB records: {len(pm_df)}\")\n",
    "# print(f\"MERRA records: {len(merra_df)}\")\n",
    "\n",
    "# ---------- Step 4: Merge All ----------\n",
    "combined_df = pd.merge(aod_df, pm_df, on=\"Date\")\n",
    "# print(f\"After merging AOD + CPCB: {len(combined_df)} records\")\n",
    "\n",
    "combined_df = pd.merge(combined_df, merra_df, on=\"Date\")\n",
    "# print(f\"After merging with MERRA: {len(combined_df)} records\")\n",
    "\n",
    "# print(\"🔍 AOD dates:\", aod_df['Date'].unique())\n",
    "# print(\"🔍 CPCB dates:\", pm_df['Date'].unique())\n",
    "# print(\"🔍 MERRA dates:\", merra_df['Date'].unique())\n",
    "\n",
    "\n",
    "# ---------- Step 5: ML Model ----------\n",
    "features = ['Mean_AOD', 'PS', 'QV2M', 'T2M', 'TS', 'U10M', 'QV10M', 'SLP', 'T10M', 'T2MDEW', 'TQI', 'TQL']\n",
    "clean_df = combined_df.dropna(subset=features + ['PM2.5 (µg/m³)'])\n",
    "\n",
    "# Create feature matrix and target vector\n",
    "X = clean_df[features].copy()\n",
    "y = clean_df['PM2.5 (µg/m³)']\n",
    "\n",
    "# Optional feature engineering\n",
    "X['Temp_Diff'] = X['TS'] - X['T2M']\n",
    "X['Humidity_Ratio'] = X['QV2M'] / (X['T2M'] + 1e-3)  # prevent division by zero\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"✅ Evaluation:\")\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print(\"R²:\", r2_score(y_test, y_pred))\n",
    "\n",
    "# # ---------- Step 6: Predict for 20 June ----------\n",
    "# # Replace with actual June 20 values from your MERRA and AOD\n",
    "may_11 = {\n",
    "    \"Mean_AOD\": [0.97],\n",
    "    \"PS\": [98119.390],\n",
    "    \"QV2M\": [0.007],\n",
    "    \"T2M\": [313.68],\n",
    "    \"TS\": [316.82],\n",
    "    \"U10M\": [2.75],\n",
    "    \"QV10M\": [0.007],\n",
    "    \"SLP\": [100396.60],\n",
    "    \"T10M\": [312.85],\n",
    "    \"T2MDEW\": [283.28],\n",
    "    \"TQI\": [0.0],\n",
    "    \"TQL\": [0.0],\n",
    "}\n",
    "may_11_df = pd.DataFrame(may_11)\n",
    "\n",
    "# Recreate engineered features\n",
    "may_11_df['Temp_Diff'] = may_11_df['TS'] - may_11_df['T2M']\n",
    "may_11_df['Humidity_Ratio'] = may_11_df['QV2M'] / (may_11_df['T2M'] + 1e-3)\n",
    "\n",
    "# Ensure columns match training\n",
    "X_input = may_11_df[X_train.columns]\n",
    "\n",
    "# Predict\n",
    "pred_pm = rf.predict(X_input)\n",
    "print(\"\\n🔮 Predicted PM2.5 for 11 May 2024 at 05:30 IST:\", pred_pm[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74f151a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Keys in file: ['AOD', 'latitude', 'longitude', 'time']\n",
      "📐 AOD shape: (1, 551, 551)\n",
      "🧭 Latitude shape: (551,)\n",
      "🧭 Longitude shape: (551,)\n",
      "🔎 Nearest index — lat: 166 lon: 322\n",
      "📌 AOD value at Faridabad: 0.779472\n",
      "📆 Date parsed from filename: 2024-05-01\n",
      "✅ Final Record: {'Date': datetime.date(2024, 5, 1), 'Mean_AOD': 0.779472}\n"
     ]
    }
   ],
   "source": [
    "#To read AOD value from a single .h5 file\n",
    "import h5py\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# 📍 Location of interest: Faridabad (approx.)\n",
    "target_lat = 28.4\n",
    "target_lon = 77.3\n",
    "\n",
    "# 📄 Path to one .h5 file (example)\n",
    "file_path = \"aod_folder/3DIMG_01MAY2024_0530_L2G_AOD_V02R00.h5\"\n",
    "\n",
    "# ✅ Read and extract AOD value\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    print(\"🔍 Keys in file:\", list(f.keys()))  # Show root-level keys\n",
    "\n",
    "    # Check if required datasets are present\n",
    "    if 'AOD' in f and 'latitude' in f and 'longitude' in f:\n",
    "        aod_data = f['AOD'][:]           # 2D array of AOD\n",
    "        latitudes = f['latitude'][:]     # 1D array\n",
    "        longitudes = f['longitude'][:]   # 1D array\n",
    "\n",
    "        print(\"📐 AOD shape:\", aod_data.shape)\n",
    "        print(\"🧭 Latitude shape:\", latitudes.shape)\n",
    "        print(\"🧭 Longitude shape:\", longitudes.shape)\n",
    "\n",
    "        # Find nearest grid index to target lat/lon\n",
    "        lat_idx = (np.abs(latitudes - target_lat)).argmin()\n",
    "        lon_idx = (np.abs(longitudes - target_lon)).argmin()\n",
    "        print(\"🔎 Nearest index — lat:\", lat_idx, \"lon:\", lon_idx)\n",
    "\n",
    "        # Handle possible shape issues\n",
    "        try:\n",
    "            aod_value = aod_data[0, lat_idx, lon_idx]\n",
    "            print(\"📌 AOD value at Faridabad:\", aod_value)\n",
    "        except IndexError as e:\n",
    "            print(\"❌ IndexError while accessing AOD value:\", e)\n",
    "            aod_value = np.nan\n",
    "    else:\n",
    "        print(\"❌ One or more required datasets not found in file.\")\n",
    "        aod_value = np.nan\n",
    "\n",
    "    # Parse date from filename\n",
    "    filename = os.path.basename(file_path)\n",
    "    try:\n",
    "        date_str = filename.split(\"_\")[1]  # '01JUN2024'\n",
    "        date_obj = datetime.strptime(date_str, \"%d%b%Y\").date()\n",
    "        print(\"📆 Date parsed from filename:\", date_obj)\n",
    "    except Exception as e:\n",
    "        print(\"❌ Error parsing date from filename:\", e)\n",
    "        date_obj = None\n",
    "\n",
    "    # Store result\n",
    "    record = {\n",
    "        \"Date\": date_obj,\n",
    "        \"Mean_AOD\": aod_value\n",
    "    }\n",
    "\n",
    "print(\"✅ Final Record:\", record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7935251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved all AOD values to aod_data.csv\n"
     ]
    }
   ],
   "source": [
    "#Merging all the .h5 into a single csv file\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "def extract_aod_from_folder(folder_path):\n",
    "    records = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".h5\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                with h5py.File(file_path, 'r') as f:\n",
    "                    # Ensure keys exist (some files might be corrupt)\n",
    "                    if 'AOD' not in f or 'latitude' not in f or 'longitude' not in f:\n",
    "                        continue\n",
    "\n",
    "                    aod_data = f['AOD'][:]\n",
    "                    latitudes = f['latitude'][:]\n",
    "                    longitudes = f['longitude'][:]\n",
    "\n",
    "                    # Find nearest point to Faridabad\n",
    "                    lat_idx = (np.abs(latitudes - 28.4)).argmin()\n",
    "                    lon_idx = (np.abs(longitudes - 77.3)).argmin()\n",
    "\n",
    "                    # Fix for shape mismatch\n",
    "                    if aod_data.ndim == 3 and lat_idx < aod_data.shape[1] and lon_idx < aod_data.shape[2]:\n",
    "                        aod_val = aod_data[0, lat_idx, lon_idx]\n",
    "                    else:\n",
    "                        aod_val = np.nan  # skip if shape mismatch\n",
    "\n",
    "                    # Extract date from filename\n",
    "                    date_str = filename.split(\"_\")[1]  # '01JUN2024'\n",
    "                    date_obj = datetime.strptime(date_str, \"%d%b%Y\").date()\n",
    "\n",
    "                    records.append({\n",
    "                        \"Date\": date_obj,\n",
    "                        \"Mean_AOD\": aod_val\n",
    "                    })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Failed for {filename}: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# 🔁 Extract from all files\n",
    "aod_df = extract_aod_from_folder(\"aod_folder\")\n",
    "\n",
    "# 💾 Save to CSV\n",
    "aod_df.to_csv(\"aod_data.csv\", index=False)\n",
    "print(\"✅ Saved all AOD values to aod_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c1197b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PS': [98119.390625], 'QV2M': [0.007875049486756325], 'T2M': [313.6807861328125], 'TS': [316.8280334472656], 'U10M': [2.7565226554870605], 'QV10M': [0.007863740436732769], 'SLP': [100396.609375], 'T10M': [312.8543701171875], 'T2MDEW': [283.28582763671875], 'TQI': [0.0], 'TQL': [0.0]}\n"
     ]
    }
   ],
   "source": [
    "#Reading the MERRA Varible values from the file\n",
    "import xarray as xr\n",
    "\n",
    "# Load NetCDF file\n",
    "file_path = \"merra_downloads\\MERRA2_400.tavg1_2d_slv_Nx.20240511.SUB.nc\"\n",
    "ds = xr.open_dataset(file_path)\n",
    "\n",
    "# 🔍 Step 1: Define coordinates of Faridabad (approx)\n",
    "target_lat = 28.41\n",
    "target_lon = 77.31\n",
    "\n",
    "# 🔍 Step 2: Select the nearest location\n",
    "nearest_lat = ds.sel(lat=target_lat, method=\"nearest\").lat.values\n",
    "nearest_lon = ds.sel(lon=target_lon, method=\"nearest\").lon.values\n",
    "\n",
    "# 🔍 Step 3: Select the first time step (if only one day is present)\n",
    "time_step = ds.time.values[0]\n",
    "\n",
    "# 🔍 Step 4: Extract values for each variable at that location and time\n",
    "may_11 = {\n",
    "    \"PS\":     [float(ds[\"PS\"].sel(time=time_step, lat=nearest_lat, lon=nearest_lon).values)],\n",
    "    \"QV2M\":   [float(ds[\"QV2M\"].sel(time=time_step, lat=nearest_lat, lon=nearest_lon).values)],\n",
    "    \"T2M\":    [float(ds[\"T2M\"].sel(time=time_step, lat=nearest_lat, lon=nearest_lon).values)],\n",
    "    \"TS\":     [float(ds[\"TS\"].sel(time=time_step, lat=nearest_lat, lon=nearest_lon).values)],\n",
    "    \"U10M\":   [float(ds[\"U10M\"].sel(time=time_step, lat=nearest_lat, lon=nearest_lon).values)],\n",
    "    \"QV10M\":   [float(ds[\"QV10M\"].sel(time=time_step, lat=nearest_lat, lon=nearest_lon).values)],\n",
    "    \"SLP\":   [float(ds[\"SLP\"].sel(time=time_step, lat=nearest_lat, lon=nearest_lon).values)],\n",
    "    \"T10M\":   [float(ds[\"T10M\"].sel(time=time_step, lat=nearest_lat, lon=nearest_lon).values)],\n",
    "    \"T2MDEW\":   [float(ds[\"T2MDEW\"].sel(time=time_step, lat=nearest_lat, lon=nearest_lon).values)],\n",
    "    \"TQI\":   [float(ds[\"TQI\"].sel(time=time_step, lat=nearest_lat, lon=nearest_lon).values)],\n",
    "    \"TQL\":   [float(ds[\"TQL\"].sel(time=time_step, lat=nearest_lat, lon=nearest_lon).values)],\n",
    "    # \"U2M\":   [float(ds[\"U2M\"].sel(time=time_step, lat=nearest_lat, lon=nearest_lon).values)],\n",
    "    # \"Mean_AOD\": [0.97]  # Add manually or fetch from INSAT/CPCB if needed\n",
    "}\n",
    "\n",
    "print(may_11)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
